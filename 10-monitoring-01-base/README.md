# Домашнее задание к занятию "10.01. Зачем и что нужно мониторить"

## Обязательные задания

1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя 
платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой 
осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы
выведите в мониторинг и почему?


### Ответ

Клиент явно желает предотвратить сбои в работе сервиса, поэтому будем использовать
whitebox-мониторинг, чтобы иметь возможность прогнозировать работу систему ДО возникновения проблем
у пользователя.

С целью своевременного выявления сбоев в работе сервиса мониторинг должен охватывать всю цепочку
взаимодействия пользователь-система.

В данном случае цепочка следующим образом: HTTP-запрос -> Balancer (Reverse Proxy Server) ->
Веб-сервер (один или несколько)  -> Сервер, на котором работает платформа (один или несколько) ->
Сгенерированный текстовый отчет -> Жесткий диск (один или несколько).

Для компонентов системы предлагаются следующие метрики (здесь каждой метрики указаны
пороговые значения уровней **WARNING** / **CRITICAL**)*:

| Метрика                    |  Balancer  |  Web-Server  | DB server |
|:---------------------------|:----------:|:------------:|:---------:|
| RAM usage (Free/Total)     | 50% / 80%  |  75% / 90%   | 50% / 75% |
| CPU Load Average           | 75% / 90%  |  75% / 90%   | 30% / 50% | 
| I/O wait (per CPU core)    | 1.0 / 1.5  |  0.8 / 1.0   | 0.5 / 0.8 |
| LAN usage (Current/Max)    | 75% / 90%  |  75% / 90%   | 75% / 90% |
| iNodes usage (Current/Max) | 20% / 50%  |  50% / 80%   | 50% / 80% |
| Disk Space Usage           | 50% / 80%  |  50% / 80%   | 50% / 75% |

> *Конкретные пороговые значения могут меняться в зависимости от применяемого оборудования и ПО
> и подбираются эмпирическим путём.

Для каждого компонента системы мы отслеживаем состояние памяти, загрузку процессора, сети,
файловой системы и остаток свободного места на диске.

При этом у каждого компонента есть свои особенности:
- **Balancer (Reverse Proxy Server)** - метрики используются не столько для понимания нагрузки на
сам компонент (хотя и для этого тоже), сколько для раннего обнаружения повышенной входной нагрузки
(приток клиентов, DDOS-атаки и т.д);
- **Web-Server** имеет стандартные показатели нагрузки на систему;
- **DB Server** в основном выполняет операции чтения/записи на диск, повышенная нагрузка на CPU для
него не очень свойственна и, в то же время, следует быть осторожным с наличием свободной памяти,
которая активно востребуется при коммитах транзакций и в случае её недостатка инициируются
swap-операции, сильно тормозящие систему.

---

2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, 
что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы 
можете ему предложить?


### Ответ

Объясним суть предложенных к мониторингу показателей на доступном менеджеру языке.

Показатели RAM, iNodes, CPU Load Average, а также ряд других позволяют понять, насколько нагружена
в данный момент система.

Мы не используем какой-то один показатель, потому что проблемы имеют разнородный характер и
нужно знать источник и возможную причину их возникновения, ликвидация которых производится разными
способами. Поэтому показателей несколько. Мы используем их минимум и самых основных.

Когда эти показатели начинают приближаться к некоторым
границам, то это свидетельствуют, что скоро проявятся проблемы. Но благодаря этим показателям мы
в состоянии эти проблемы заметить раньше наших клиентов и предотвратить появление неудобств.

Клиенты понимают, что для работы любой технической системы необходимо периодически производить
её обслуживание, что может вызывать некоторые неудобства при её использовании, например, временная
недоступность сервисов или падение скорости их работы.
Однако, такие периоды кратковременны, не оказывают значительного влияния
на бизнес и клиент до некоторой степени готов с этим мириться.
Степень недоступности систем является объектом соглашения
между поставщиком и потребителем сервиса и сформулирована в **Service Level Agreement (SLA)**.
Таким образом формализуются ожидания клиента от сервиса и, соответственно, наши обязательства перед
ним.

Как результат, мы имеем некий целевой уровень готовности нашей системы к работе, формализованный
в другом документе - **Service Level Objectives (SLO)**. Это тот уровень работоспособности системы,
который мы обязаны поддерживать. Полное соответствие **SLO** и
**SLA** означает 100% удовлетворенность клиента качеством работы нашей системы
(даже если по факту система работает медленно, но клиента это полностью устраивает - это всё равно
100%-я удовлетворенность, потому что это то, что клиент получает за свои вложения в сервис).

Естественно, если клиент не получает то, на что он рассчитывает и платит, то он вправе рассчитывать
на соответствующую компенсацию, что тоже м.б. прописано в **Service Level Agreement**.

Для понимания и формализации фактического уровня удовлетворенности клиента нашим сервисом мы
должны соотнести предоставляемый уровень сервиса с оговоренным. Это м.б. выражено пропорцией
объективно зафиксированных показателей (метрик) работы системы с зафиксированными в **SLA**.
Такой показатель называется **Service Level Indicators (SLI)**.

Таким образом, значение показателя **SLI** ниже 1.0 означает, что клиент не получает должного
качества услуг, а выше 1.0 - что, возможно, мы переплачиваем за инфраструктуру и есть возможность
сэкономить.  

Как результат, оперируя показателями **SLA/SLO/SLI** мы можем иметь довольно точное представление
о качестве предоставляемого нами обслуживания наших клиентов и эффективности нашего бизнеса.

---

3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою 
очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, 
чтобы разработчики получали ошибки приложения?


### Ответ

Рабора с логами в основном состоит из трех задач - сбор, консолидация и очистка.

Здесь у нас ровно два пути - воспользоваться существующими решениями по-умолчанию или создать своё.

#### Решение по-умолчанию

В мире Linux существуют несколько популярных сервисов управления логов и один из них - это
`syslog`, слушающий сообщения через сокет `/dev/log`. Приложения могут отправлять сообщения на этот
сокет, а `syslog`, в свою очередь, умеет записывать такие сообщения в локальный файл или пересылать
их на удалённый сервер.
Также существует сервис `rsyslog`, являющийся модификацией `syslog`, быстрый, многопоточный,
поддерживает фильтрацию контента, настройку формата вывода, передачу логов по сети по сетевым 
протоколам TCP, UDP, SSL, TLS и RELP.

> `syslog` использует транспортный протокол
> [RFC5424](https://datatracker.ietf.org/doc/html/rfc5424#section-6), определяющий, как пересылать
> логи по сети. Использует порт `514` для простого текста и `6514` для шифрованного.
> Определяет формат данных сообщения, состоящий из:
> - стандартизированный заголовок:
>   - приоритет сообщения;
>   - версия; 
>   - метка времени;
>   - имя хоста;
>   - имя приложения;
>   - идентификатор процесса;
> - структурированное сообщение:
>   - текст сообщения; 
>   - поля вида "ключ=значение"

#### Собственное решение

Стандартной папкой хранения сообщений в Lunux является `/var/log/`, где сохраняются логи ОС,
сервисов и приложения. Кроме того, естественно, приложения могут хранить собственные сообщения
в произвольных директориях.

Соответственно, на нужно принять решение, где будут храниться логи разрабатываемых приложений, и
после этого разработать простое приложение, автоматизирующее их фильтрацию (например, собирать
сообщения с определенным уровнем детализации в определенные файлы) и очистку (например, логи
превышающие определенный размер, сокращаются с помощью `truncate`).

#### Принятое решение

С учетом того, что бюжет не выделен, а времени на написание приложения, как обычно, ни у кого нет,
выбираем первый вариант и ограничиваемся настройкой сервиса сбора логов, стандартного для данной OC
(`syslog`, `rsyslog`, `journal` и т.д.). Как правило, такая настройка сводится к настройке
конфигурационного файла.

Разработчикам предлагается смотреть текстовый файл лога, назначенный определенному приложению.

---

4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. 
Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 
70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?


### Ответ

Все коды статусов ответа сервера при запросах по протоколу HTTP делятся на 5 классов:
- 1xx - информационные, сообщающие информацию о процессе передачи;
- 2xx - успех принятия и обработка запроса клиента;
- 3xx - перенаправление запроса;
- 4xx - ошибка со стороны клиента;
- 5xx - ошибка на стороне сервера (необработанные исключения).

Соответственно, для получения **100% результата в ситуации полного успеха** наша формула должна иметь вид:

SLI = (summ_1xx_requests + summ_2xx_requests + summ_3xx_requests) / summ_all_requests;

Но с учётом того, что сообщения класса `1xx` являются чисто информационными
(а в протоколе `HTTP 1.0` они и вовсе игнорируются), наша формула приобретает вид:

**SLI = (summ_2xx_requests + summ_3xx_requests) / summ_all_requests;**

Т.е. ошибка была в том, что не учитывались ответы со статусом `3xx` ("перенаправление"). 

---

## Дополнительное задание (со звездочкой*) - необязательно к выполнению

Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему 
мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как 
опытный системный-администратор, знаете, что системная информация сервера лежит в директории `/proc`. 
Также, вы знаете, что в системе Linux есть  планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:
- является python3 скриптом
- собирает метрики из папки `/proc`
- складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log 
(YY - год, MM - месяц, DD - день)
- каждый сбор метрик складывается в виде json-строки, в виде:
  + timestamp (временная метка, int, unixtimestamp)
  + metric_1 (метрика 1)
  + metric_2 (метрика 2)
  
     ...
     
  + metric_N (метрика N)
  
- сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,

б) конфигурацию cron-расписания,

в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,

P.S.: количество собираемых метрик должно быть не менее 4-х.
P.P.S.: по желанию можно себя не ограничивать только сбором метрик из `/proc`.


### Ответ

Директория `/proc` содержит иерархию специальных файлов, представляющих текущее состояне ядра.

Нумерованные директории представляют собой процессы. Прочие файлы предоставляют информацию о системе
и её текущем состоянии.

Например:

`loadavg` – предоставляет информацию о средней загрузке системы:
````bash
$ cat loadavg        
0.90 1.06 1.30 1/1160 558003
````

где каждая колонка предоставляет следующую информацию:
  - за 1 минуту;
  - за 5 минут;
  - за 15 минут;
  - количество выполняемых процессов / общее количество процессов в системе;
  - PID процесса, выделенный системой.

> Статистика за 1, 5 и 15 минут является условной и её разбор выходит за рамки данного задания.

`meminfo` - предоставляет сведения об используемой памяти, включая общий доступный объём (в первых 3 строках):
````bash
$ cat meminfo
MemTotal:       65730800 kB
MemFree:        35848024 kB
MemAvailable:   54476556 kB
Buffers:         2771700 kB
Cached:         16317936 kB
SwapCached:            0 kB
Active:          6193472 kB
Inactive:       20277460 kB
...
````

Здесь мы создали [программу](./python3-cron-logger), считывающую некоторые данные из этих двух файлов и сохраняющие их в
файлах логов с форматом имени `YY-MM-DD-awesome-monitoring.log`, где YY - год, MM - месяц,
а DD - день снятия данных.

Непосредственно использовать вызов команды `crontab` не нужно -
[сборщик метрик](./python3-cron-logger/metric_collector.py),
назначается планировщику с помощью вызова другого скрипта -
[активатора](./python3-cron-logger/activator.py), а снимается из заданий
с помощью третьего скрипта - [деактиватора](./python3-cron-logger/deactivator.py).

Соответственно, активация сборщика логов выглядит следующим образом:
````bash
$ python3 activator.py  
* * * * * python3 /home/oleg/DevOps/python/python3-cron-logger/metric_collector.py
````

После постановки задачи в расписание планировщика в информационных целях в консоль выводится
команда, которая может быть использована для аналогичного планирования
задачи непосредственно из командной строки.

Проверить наличие задачи в расписании можно стандартным способом:
````bash
$ crontab -l                     

* * * * * python3 /home/oleg/DevOps/python/python3-cron-logger/metric_collector.py
````

> Здесь запись `* * * * *` является инструкцией, описывающей в какую
> минуту, час, день месяца, месяц и день недели должна быть запущена задача.
> 
> `*` оздачает "каждый" и т.о. запуск будет осуществляться в "каждую минуту каждого часа каждого
> дня месяца каждого месяца каждого дня недели", т.е. просто каждую минуту.

Снимается задача аналогичным образом:
````bash
$ python3 deactivator.py

$ crontab -l

````
Собранные метрики располагаются в соответствующей [папке логов](./python3-cron-logger/log). Может
использоваться произвольная директория.

Для демонстрации работы алгоритма мы собрали логи на стыке двух дней - логи, относящиеся к
каждой дате, расположены в соответствующих файлах:
[22-06-23-awesome-monitoring.log](./python3-cron-logger/log/22-06-23-awesome-monitoring.log) и
[22-06-24-awesome-monitoring.log](./python3-cron-logger/log/22-06-24-awesome-monitoring.log).

В соответствии с [нашим алгоритмом](./python3-cron-logger/metric_collector.py) в каждом файле логов
содержатся следующие колонки (в виде JSON-представления массива):
- UNIX-метка времени;
- средняя загрузка за 1 минуту; 
- средняя загрузка за 5 минуту;
- средняя загрузка за 15 минут;
- общий объем памяти;
- объем свободной памяти;
- объем доступной памяти;

Таким образом мы организовали сбор метрик системы с разбивкой по датам. 

---
